{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from utils.progress import WorkSplitter, inhour\n",
    "from scipy.sparse import vstack, hstack\n",
    "from utils.regularizers import Regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class IFVAE(object):\n",
    "\n",
    "    def __init__(self, observation_dim, latent_dim, batch_size,\n",
    "                 lamb=0.01,\n",
    "                 beta=0.2,\n",
    "                 learning_rate=1e-4,\n",
    "                 optimizer=tf.train.RMSPropOptimizer,\n",
    "                 observation_distribution=\"Gaussian\", # or Bernoulli or Multinomial\n",
    "                 observation_std=0.01):\n",
    "\n",
    "        self._lamb = lamb\n",
    "        self._latent_dim = latent_dim\n",
    "        self._batch_size = batch_size\n",
    "        self._observation_dim = observation_dim\n",
    "        self._learning_rate = learning_rate\n",
    "        self._optimizer = optimizer\n",
    "        self._observation_distribution = observation_distribution\n",
    "        self._observation_std = observation_std\n",
    "        self._build_graph()\n",
    "\n",
    "    def _build_graph(self):\n",
    "\n",
    "        with tf.variable_scope('ifvae'):\n",
    "            self.input = tf.placeholder(tf.float32, shape=[None, self._observation_dim], name='input')\n",
    "            self.corruption = tf.placeholder(tf.float32)\n",
    "            self.sampling = tf.placeholder(tf.bool)\n",
    "\n",
    "            mask1 = tf.nn.dropout(tf.ones_like(self.input), 1-self.corruption)\n",
    "            mask2 = tf.nn.dropout(tf.ones_like(self.input), 1-self.corruption)\n",
    "\n",
    "            wc = self.input * mask1\n",
    "            hc = wc * mask2\n",
    "\n",
    "            with tf.variable_scope('network'):\n",
    "                self.wc_mean, wc_log_std, self.wc_obs_mean = self._network(wc)\n",
    "            with tf.variable_scope('network', reuse=True):\n",
    "                self.hc_mean, hc_log_std, self.hc_obs_mean = self._network(hc)\n",
    "\n",
    "            self.wc_std = tf.exp(wc_log_std)\n",
    "\n",
    "            with tf.variable_scope('loss'):\n",
    "                with tf.variable_scope('kl-divergence'):\n",
    "                    kl1 = self._kl_diagnormal_stdnormal(self.wc_mean, wc_log_std,\n",
    "                                                        self.hc_mean, hc_log_std)\n",
    "                    kl2 = self._kl_diagnormal_stdnormal(self.hc_mean, hc_log_std,\n",
    "                                                        tf.zeros_like(self.hc_mean),\n",
    "                                                        tf.zeros_like(hc_log_std))\n",
    "\n",
    "                if self._observation_distribution == 'Gaussian':\n",
    "                    with tf.variable_scope('gaussian'):\n",
    "                        floor_mask1 = tf.floor(mask1)\n",
    "                        floor_mask2 = tf.floor(mask2)\n",
    "                        obj1 = self._gaussian_log_likelihood(self.input * floor_mask1 * (1 - floor_mask2),\n",
    "                                                             self.wc_obs_mean * floor_mask1 * (1 - floor_mask2),\n",
    "                                                             self._observation_std)\n",
    "                        obj2 = self._gaussian_log_likelihood(self.input * floor_mask1 * floor_mask2,\n",
    "                                                             self.hc_obs_mean * floor_mask1 * floor_mask2,\n",
    "                                                             self._observation_std)\n",
    "                elif self._observation_distribution == 'Bernoulli':\n",
    "                    with tf.variable_scope('bernoulli'):\n",
    "                        obj1 = self._bernoulli_log_likelihood(self.input * tf.floor(mask1) * (1 - tf.floor(mask2)),\n",
    "                                                              self.wc_obs_mean * tf.floor(mask1) * (1 - tf.floor(mask2)))\n",
    "                        obj2 = self._bernoulli_log_likelihood(self.input * tf.floor(mask1) * tf.floor(mask2),\n",
    "                                                              self.hc_obs_mean * tf.floor(mask1) * tf.floor(mask2))\n",
    "\n",
    "                else:\n",
    "                    with tf.variable_scope('multinomial'):\n",
    "                        obj1 = self._multinomial_log_likelihood(self.input * tf.floor(mask1) * (1 - tf.floor(mask1)),\n",
    "                                                                self.wc_obs_mean * tf.floor(mask1) * (1 - tf.floor(mask1)))\n",
    "                        obj2 = self._multinomial_log_likelihood(self.input * tf.floor(mask1) * tf.floor(mask2),\n",
    "                                                                self.hc_obs_mean * tf.floor(mask1) * tf.floor(mask2))\n",
    "\n",
    "                with tf.variable_scope('l2'):\n",
    "                    l2_loss = tf.reduce_mean(tf.nn.l2_loss(self.encode_weights) + tf.nn.l2_loss(self.decode_weights))\n",
    "\n",
    "                self._loss = ((kl1 + kl2 + obj1 + obj2) + self._lamb * l2_loss) * (1 - self.corruption)\n",
    "\n",
    "            with tf.variable_scope('optimizer'):\n",
    "                optimizer = self._optimizer(learning_rate=self._learning_rate)\n",
    "            with tf.variable_scope('training-step'):\n",
    "                self._train = optimizer.minimize(self._loss)\n",
    "\n",
    "            self.sess = tf.Session()\n",
    "            init = tf.global_variables_initializer()\n",
    "            self.sess.run(init)\n",
    "\n",
    "    def _network(self, x):\n",
    "        with tf.variable_scope('encoder'):\n",
    "            self.encode_weights = tf.Variable(tf.truncated_normal([self._observation_dim, self._latent_dim * 2],\n",
    "                                                                   stddev=1 / 500.0),\n",
    "                                         name=\"Weights\")\n",
    "            encode_bias = tf.Variable(tf.constant(0., shape=[self._latent_dim * 2]), name=\"Bias\")\n",
    "\n",
    "            encoded = tf.matmul(x, self.encode_weights) + encode_bias\n",
    "\n",
    "        with tf.variable_scope('latent'):\n",
    "            mean = tf.nn.relu(encoded[:, :self._latent_dim])\n",
    "            logstd = encoded[:, self._latent_dim:]\n",
    "            std = tf.exp(logstd)\n",
    "            epsilon = tf.random_normal(tf.shape(std))\n",
    "            z = mean\n",
    "\n",
    "            z = tf.cond(self.sampling, lambda: z + std * epsilon, lambda: z)\n",
    "\n",
    "        with tf.variable_scope('decoder'):\n",
    "            self.decode_weights = tf.Variable(\n",
    "                tf.truncated_normal([self._latent_dim, self._observation_dim], stddev=1 / 500.0),\n",
    "                name=\"Weights\")\n",
    "            self.decode_bias = tf.Variable(tf.constant(0., shape=[self._observation_dim]), name=\"Bias\")\n",
    "            decoded = tf.matmul(z, self.decode_weights) + self.decode_bias\n",
    "\n",
    "            obs_mean = decoded\n",
    "\n",
    "        return mean, logstd, obs_mean\n",
    "\n",
    "    @staticmethod\n",
    "    def _kl_diagnormal_stdnormal(mu_1, log_std_1, mu_2=0, log_std_2=0):\n",
    "\n",
    "        log_std_2 = tf.where(tf.less(log_std_2, -10), tf.ones(tf.shape(log_std_2)) * -10, log_std_2)\n",
    "\n",
    "        var_square_1 = tf.exp(2. * log_std_1)\n",
    "        var_square_2 = tf.exp(2. * log_std_2)\n",
    "        kl = 0.5 * tf.reduce_mean(2 * log_std_2 - 2. * log_std_1\n",
    "                                  + tf.divide(var_square_1 + tf.square(mu_1-mu_2), var_square_2) - 1.)\n",
    "        return kl\n",
    "\n",
    "    @staticmethod\n",
    "    def _gaussian_log_likelihood(targets, mean, std):\n",
    "        se = 0.5 * tf.reduce_mean(tf.square(targets - mean)) / (2*tf.square(std)) + tf.log(std)\n",
    "        return se\n",
    "\n",
    "    @staticmethod\n",
    "    def _bernoulli_log_likelihood(targets, outputs, eps=1e-8):\n",
    "\n",
    "        log_like = -tf.reduce_mean(targets * tf.log(outputs + eps)\n",
    "                                   + (1. - targets) * tf.log((1. - outputs) + eps))\n",
    "        return log_like\n",
    "\n",
    "    @staticmethod\n",
    "    def _multinomial_log_likelihood(target, outputs, eps=1e-8):\n",
    "        log_softmax_output = tf.nn.log_softmax(outputs)\n",
    "        log_like = -tf.reduce_sum(tf.reduce_sum(log_softmax_output * target, axis=1))\n",
    "        return log_like\n",
    "\n",
    "    def update(self, x, corruption):\n",
    "        _, loss = self.sess.run([self._train, self._loss],\n",
    "                                 feed_dict={self.input: x, self.corruption: corruption, self.sampling: True})\n",
    "        return loss\n",
    "\n",
    "    def inference(self, x):\n",
    "        predict = self.sess.run(self.wc_obs_mean,\n",
    "                                 feed_dict={self.input: x, self.corruption: 0, self.sampling: False})\n",
    "        return predict\n",
    "\n",
    "    def uncertainty(self, x):\n",
    "        gaussian_parameters = self.sess.run([self.wc_mean, self.wc_std],\n",
    "                                             feed_dict={self.input: x, self.corruption: 0, self.sampling: False})\n",
    "\n",
    "        return gaussian_parameters\n",
    "\n",
    "    def train_model(self, rating_matrix, corruption, epoch=100, batches=None, **unused):\n",
    "        if batches is None:\n",
    "            batches = self.get_batches(rating_matrix, self._batch_size)\n",
    "\n",
    "        # Training\n",
    "        pbar = tqdm(range(epoch))\n",
    "        for i in pbar:\n",
    "            for step in range(len(batches)):\n",
    "                corrupt_rate = random.uniform(0.1, 0.5)\n",
    "                feed_dict = {self.input: batches[step].todense(), self.corruption: corrupt_rate, self.sampling: True}\n",
    "                training, loss = self.sess.run([self._train, self.wc_std], feed_dict=feed_dict)\n",
    "                pbar.set_description(\"loss: {:.4f}\".format(np.mean(loss)))\n",
    "\n",
    "    def get_batches(self, rating_matrix, batch_size):\n",
    "        remaining_size = rating_matrix.shape[0]\n",
    "        batch_index = 0\n",
    "        batches = []\n",
    "        while remaining_size > 0:\n",
    "            if remaining_size < batch_size:\n",
    "                batches.append(rating_matrix[batch_index*batch_size:])\n",
    "            else:\n",
    "                batches.append(rating_matrix[batch_index*batch_size:(batch_index+1)*batch_size])\n",
    "            batch_index += 1\n",
    "            remaining_size -= batch_size\n",
    "        return batches\n",
    "\n",
    "    def get_RQ(self, rating_matrix):\n",
    "        batches = self.get_batches(rating_matrix, self._batch_size)\n",
    "        RQ = []\n",
    "        for step in range(len(batches)):\n",
    "            feed_dict = {self.input: batches[step].todense(), self.corruption: 0, self.sampling: False}\n",
    "            embedding = self.sess.run(self.wc_mean, feed_dict=feed_dict)\n",
    "            RQ.append(embedding)\n",
    "\n",
    "        return np.vstack(RQ)\n",
    "\n",
    "    def get_Y(self):\n",
    "        return self.sess.run(self.decode_weights)\n",
    "\n",
    "    def get_Bias(self):\n",
    "        return self.sess.run(self.decode_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ifvae(matrix_train, embeded_matrix=np.empty((0)), iteration=100,\n",
    "          lam=80, rank=200, corruption=0.2, optimizer=\"RMSProp\", seed=1, **unused):\n",
    "    progress = WorkSplitter()\n",
    "    matrix_input = matrix_train\n",
    "    if embeded_matrix.shape[0] > 0:\n",
    "        matrix_input = vstack((matrix_input, embeded_matrix.T))\n",
    "\n",
    "    m, n = matrix_input.shape\n",
    "    model = IFVAE(n, rank, 100, lamb=lam, observation_distribution=\"Gaussian\", optimizer=Regularizer[optimizer])\n",
    "\n",
    "    model.train_model(matrix_input, corruption, iteration)\n",
    "\n",
    "    RQ = model.get_RQ(matrix_input)\n",
    "    Y = model.get_Y()\n",
    "    Bias = model.get_Bias()\n",
    "    model.sess.close()\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    return RQ, Y, Bias"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
